{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "data_dir = 'dataset'\n",
    "\n",
    "real_data = [f for f in os.listdir(data_dir+'/real') if f.endswith('.png')]\n",
    "fake_data = [f for f in os.listdir(data_dir+'/fake') if f.endswith('.png')]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img in real_data:\n",
    "    X.append(img_to_array(load_img(data_dir+'/real/'+img)).flatten() / 255.0)\n",
    "    Y.append(1)\n",
    "for img in fake_data:\n",
    "    X.append(img_to_array(load_img(data_dir+'/fake/'+img)).flatten() / 255.0)\n",
    "    Y.append(0)\n",
    "\n",
    "#Normalization\n",
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "\n",
    "#Reshape\n",
    "X = X.reshape(-1, 128, 128, 3)\n",
    "\n",
    "#Train-Test split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 2, 2, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3074      \n",
      "=================================================================\n",
      "Total params: 54,339,810\n",
      "Trainable params: 54,279,266\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "googleNet_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "googleNet_model.trainable = True\n",
    "model = Sequential()\n",
    "model.add(googleNet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2996 samples, validate on 749 samples\n",
      "Epoch 1/20\n",
      "2996/2996 [==============================] - 63s 21ms/sample - loss: 0.6901 - accuracy: 0.5511 - val_loss: 1.0586 - val_accuracy: 0.3525\n",
      "Epoch 2/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.5146 - accuracy: 0.7680 - val_loss: 0.8897 - val_accuracy: 0.4179\n",
      "Epoch 3/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.4021 - accuracy: 0.8785 - val_loss: 0.7527 - val_accuracy: 0.5180\n",
      "Epoch 4/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.3177 - accuracy: 0.9196 - val_loss: 0.6804 - val_accuracy: 0.5915\n",
      "Epoch 5/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.2471 - accuracy: 0.9436 - val_loss: 0.6173 - val_accuracy: 0.6769\n",
      "Epoch 6/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.1961 - accuracy: 0.9543 - val_loss: 0.5554 - val_accuracy: 0.7704\n",
      "Epoch 7/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.1562 - accuracy: 0.9656 - val_loss: 0.5376 - val_accuracy: 0.8131\n",
      "Epoch 8/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.1291 - accuracy: 0.9690 - val_loss: 0.5051 - val_accuracy: 0.8211\n",
      "Epoch 9/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.1040 - accuracy: 0.9776 - val_loss: 0.4700 - val_accuracy: 0.8371\n",
      "Epoch 10/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0916 - accuracy: 0.9796 - val_loss: 0.4317 - val_accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0777 - accuracy: 0.9810 - val_loss: 0.3954 - val_accuracy: 0.8758\n",
      "Epoch 12/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0676 - accuracy: 0.9806 - val_loss: 0.3565 - val_accuracy: 0.8972\n",
      "Epoch 13/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0564 - accuracy: 0.9870 - val_loss: 0.3449 - val_accuracy: 0.9079\n",
      "Epoch 14/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.3368 - val_accuracy: 0.9119\n",
      "Epoch 15/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0445 - accuracy: 0.9897 - val_loss: 0.3274 - val_accuracy: 0.9105\n",
      "Epoch 16/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.3175 - val_accuracy: 0.9159\n",
      "Epoch 17/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0363 - accuracy: 0.9923 - val_loss: 0.3101 - val_accuracy: 0.9159\n",
      "Epoch 18/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0332 - accuracy: 0.9910 - val_loss: 0.3023 - val_accuracy: 0.9266\n",
      "Epoch 19/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0305 - accuracy: 0.9927 - val_loss: 0.3018 - val_accuracy: 0.9279\n",
      "Epoch 20/20\n",
      "2996/2996 [==============================] - 21s 7ms/sample - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.3069 - val_accuracy: 0.9279\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0,\n",
    "                               patience=2,\n",
    "                               verbose=0, mode='auto')\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 100\n",
    "history = model.fit(X_train, Y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (X_val, Y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\n",
    "t = f.suptitle('Pre-trained CNN Transfer Learn with Fine-Tuning & Image Augmentation Performance ', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,EPOCHS+1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch #')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, EPOCHS+1, 1))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch #')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('deepfake-detection-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
